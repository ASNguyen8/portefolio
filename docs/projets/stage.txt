# Contexte

Dans le cadre de mon [Master MAS](/Formations), j'ai dû effectuer un stage d'une durée de 4 à 6 mois en entreprise. Je l'ai donc effectué à l'IHU Liryc sous la tutelle du professeur Rémi Dubois.

Pour présenter rapidement le Liryc, il s'agit d'un Institut Hospitalo Universitaire (IHU) situé dans le complexe hospitalier Xavier Arnozan à Pessac dédié à la recherche sur le cœur, son fonctionnement et les pathologies du rythme cardiaque. Il compte plusieurs équipes aux spécialités variées qui travaillent à faire progresser les avancées scientifiques dans le domaine du cœur.

# Problématique

Des défibrillateurs sont implantés chez des patients souffrant de pathologies du rythme cardiaque. Grâce à leur algorithme embarqué, ces défibrillateurs surveillent l'activité cardiaque des patients et peuvent appliquer une thérapie si nécessaire. Les tracés de l'activité électrique du cœur des patients, mesurée à la surface de l'organe, sont appelés des **électrogrammes** (EGM) et sont remontés aux constructeurs des défibrillateurs puis récupérés par le Centre Hospitalier Universitaire (CHU) de Bordeaux pour des analyses ultérieures.  
Parmi les pathologies cardiaques remontées par le défibrillateur, la fibrillation auriculaire (FA) n'est pas traitée par ce dernier. Or, un signal bruité ou un rythme cardiaque rapide peut être pensé comme conséquence d'une fibrillation auriculaire : l'appareil détectera alors "à tort" une FA au lieu de la bonne pathologie. Ceci peut aussi traduire un dysfonctionnement du défibrillateur. Dans les deux cas, le patient encourt de potentielles graves conséquences.  
Afin de différencier les vraies FA de celles détectées à tort sur les EGM, des médecins ont été embauchés pour faire le tri. Sur des échantillons de plus de 10,000 enregistrements, on devine que cette étape de classification manuelle requiert énormément de temps.

Au sein de l'équipe de traitement du signal, je suis donc chargé, au cours de ce stage, de trouver une développer un algorithme basé sur une stratégie de Machine Learning permettant d'automatiser cette classification d'EGM.

# Données utilisées

La base de données que j'ai utilisé comporte 10,172 électrogrammes, possédant chacun deux composantes : l'activité électrique (au cours du temps) au niveau des oreillettes (voie auriculaire) et au niveau des ventricules (voie ventriculaire). Parmi ces 10,172 enregistrements labellisés manuellement par 3 médecins différents, on compte :
 - 8057 de classe 1 (l'EGM présente bien une FA);
 - 2115 de classe 0 (l'EGM ne présente pas de FA).

La longueur des EGM varie entre 513 et 5137 points de données.

<img>img/af_algo.png|Exemple d'EGM : la voie auriculaire est tracée en noir et la voie ventriculaire en bleu. Les évènements cardiaques détectés par l'appareil sont dénotés par des marqueurs sur l'axe en bas.|300<img>

Les données des EGM sont stockés dans une arborescence sur le serveur du Liryc sous la forme suivante :  
├── dossier_EGM  
│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── 0  
│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── <EGM_classe_0.txt>  
│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── 1  
│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;│&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── <EGM_classe_1.txt>  

# Méthodologie

En suivant les directives de mon tuteur de stage, l'algorithme que je devais développer était un modèle de réseau de neurones. Celui-ci prend en entrée les deux voies des EGM sous un unique format (signaux de même taille) et retourne en sortie la probabilité d'appartenir à la classe 0 ou 1. 

La longueur des signaux étant variable, j'ai d'abord appliqué un zero-padding jusqu'à une longueur à 8192 (n'engendre aucune perte d'information) afin de les uniformiser.

J'ai ensuite procédé à un découpage apprentissage/test des données :
 - 80% de données serviront pour l'apprentissage du modèle
 - 20% pour évaluer ses performances.  

Le déséquilibre initial des classes est conservé dans les deux sous ensembles de données.

Un modèle de réseau de neurones va avoir plusieurs hyperparamètres à calibrer : 
 - son architecture (nombre de couche et nombre de neurones par couche)
 - l'algorithme d'optimisation à utiliser pour l'entraînement et son taux d'apprentissage
 - la taille des batchs de données à utiliser pendant l'entraînement
 - des poids associés à chaque classe pour l'entraînement (rajoutés ici pour compenser le déséquilibre des classes)

Pour trouver la meilleure architecture, je me suis inspiré de l'architecture des [ResNet](https://fr.wikipedia.org/wiki/R%C3%A9seau_neuronal_r%C3%A9siduel) qui comportent jusqu'à 100 couches de neurones. Cependant, je me suis limité ici à une dizaine car les données des EGM ne sont pas très complexes. En effet, une architecture trop riche en couche de neurones risque de rapidement surapprendre les données d'apprentissage, en plus d'avoir un temps d'entraînement/d'inférence plus élevé.

| Hyperparamètre | Valeurs testées |
|--|--|
| Algorithme d'optimisation | Adam, SGD, SGD avec momentum à 0.9 et 0.99 |
| Taux d'apprentissage | $10^{-1}$, $10^{-2}$, $10^{-3}$, $10^{-4}$, $10^{-5}$, $10^{-6}$, $10^{-7}$ |
| Taille des batchs | 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024 |
| Poids associé à la classe 1 | 0.5, 0.6, 2/3, 0.7, 0.8, 0.9 |
 
Le poids associé à la classe 0 a pour valeur (1 - poids associé à la classe 1).

Toutes les valeurs des hyperparamètres ont été sélectionnées par **validation croisée 5-folds**.

À noter qu'il existe d'autres paramètres : les poids de chaque couche de neurones. Cependant, ils sont initialisés aléatoirement pour un modèle puis ajustés automatiquement lors de l'étape de rétropropagation à l'entraînement.

# Validation croisée 5-Folds

L'ensemble de données d'apprentissage est découpé en 5 sous ensembles de données (5 folds), de la même façon que pour le découpage apprentissage/test.

Pour un ensemble d'hyperparamètres fixés, j'entraîne alors un modèle de réseau de neurones sur 4 folds, puis j'évalue ses performances sur le dernier fold, l'ensemble de données de validation.  
Le score utilisé ici qui permet d'évaluer la performance d'un modèle est le [**F1 score**](https://en.wikipedia.org/wiki/F-score). J'ai aussi regardé d'autres mesures comme [l'accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification), [la précision ou encore le rappel](https://en.wikipedia.org/wiki/Precision_and_recall).

Les poids des couches de neurones d'un modèle de réseau de neurones sont initialisés aléatoirement. Ceci fait qu'avec un même ensemble d'hyperparamètres (donc la même architecture) et les mêmes données d'entraînement, deux modèles verront leur poids actualisés différemment lors de l'entraînement et auront *in fine* des performances différentes.

Connaissant cette contrainte, j'ai choisi donc d'entraîner 5 modèles sur 4 folds pour les évaluer sur le dernier. Ce procédé est fait pour chaque combinaison possible de 4 folds parmi les 5. Je me retrouve donc avec 25 modèles entraînés. Pour chaque fold, je prends le meilleur score par combinaison de fold : 5 scores au total. En faisant la moyenne de ces 5 scores, j'obtiens le score moyen pour l'ensemble d'hyperparamètres fixés au départ.

Ce procédé de validation croisée est coûteux en temps (dure plusieurs jours selon les hyperparamètres). Afin d'éviter d'avoir à le faire pour chacune des $5 \times 7 \times 10 \times 6 = 2100$ combinaisons d'hyperparamètres possibles (sans compter l'architecture du modèle), j'ai supposé que la valeur sélectionnée pour un hyperparamètre l'aurait été quelque soit la valeur des autres hyperparamètres. Ainsi, en sélectionnant par exemple l'algorithme Adam comme meilleur algorithme d'optimisation (d'après le F1 score moyen sur les données de validation), je suppose que quelque soit l'architecture du réseau, ce sera le meilleur choix d'algorithme d'optimisation.

<img>img/cross_validation.svg|Schéma du procédé de validation croisée 5-Folds appliqué pour obtenir le F1 score moyen d'une architecture avec son ensemble d'hyperparamètres sur les données de validation|<img>

# Résultats

Au terme de la sélection par validation croisée 5-Folds, j'ai trouvé deux architectures de réseau de neurones qui obtient un F1 score moyen supérieur à 95% sur les données de validation. La première architecture prend en entrée les deux voies (auriculaire et ventriculaire) d'un EGM, avec un padding à 8192. Elle comporte successivement :
 - 2 couches de convolution
 - 2 couches "ResNet" (convolution avec une connection résiduelle)
 - 6 couches denses complètement connectées
 - une couche linéaire renvoyant la probabilité que l'EGM appartienne à la classe 1 et celle qu'il appartienne à la classe 0.

La seconde architecture ne prend en entrée que la voie auriculaire de l'EGM, avec un padding à 8192. celle-ci se décompose en :
 - 2 couches de convolution
 - 3 couches "ResNet"
 - 2 couches denses complètement connectées
 - une couche linéaire renvoyant la probabilité que l'EGM appartienne à la classe 1 et celle qu'il appartienne à la classe 0.

Les hyperparamètres sélectionnés pour chaque architecture se trouvent dans ce tableau :
|  | Arch. à 2 voies | Arch. à 1 voie |
|--|--|--|
| Algorithme d'optimisation | Adam | Adam |
| Taux d'apprentissage | 0.001 | 0.001 |
| Taille des batchs | 64 | 16 |
| Poids associé à la classe 1 | $2/3$ | $2/3$ |  

J'ai ensuite entraîné des modèles avec ces architectures et leur ensemble d'hyperparamètres sur la totalité des données d'apprentissage. Puis je les ai évalué sur l'ensemble de données test afin de sélectionner le modèle avec le meilleur F1 score (sur les données de test) par architecture. Les meilleurs modèles ont obtenu ces scores sur les données de test : 
|  | Arch. à 2 voies | Arch. à 1 voie |
|--|--|--|
| F1 score | 0.9290 | 0.9594 |
| Accuracy | 0.9683 | 0.9817 |
| Taux de vrais positifs | 0.9769 | 0.9892 |
| Taux de vrais négatifs | 0.9379 | 0.9558 |
| Valeur prédictive positive | 0.9822 | 0.9871 |
| Valeur prédictive négative | 0.9203 | 0.9629 |
| Balanced accuracy | 0.9574 | 0.9725 |

# Déployement 

Après avoir développé les modèles de réseaux de neurones, je les ai intégré à une application web en utilisant la librairie `Flask` afin de permettre à l'IHU Liryc de pouvoir s'en servir facilement dans le futur.

On passe à l'application un enregistrement d'électrogramme sous forme de fichier `.txt` OU une archive `.zip` contenant des enregistrements d'électrogrammes (aussi en fichier `.txt`).  
Les données passées à l'application sont traitées (padding à 8192, normalisées) puis passées aux deux modèles. Ces derniers renvoient les probabilités d'appartenir à chaque classe.  
Si on a passé un seul fichier `.txt` en entrée, les prédictions des modèles seront affichées sur l'interface web directement. Dans le cas contraire, les prédictions sont enregistrées dans un fichier `.csv` qui peut être téléchargé.

<img>img/workflow_pred.png|Schéma du fonctionnement de l'application Flask : les prédictions sont soit affichées sur l'interface web, soit envoyées dans un fichier CSV à télécharger.|<img>

L'application est utilisable est peut être déployée sur le serveur de l'établissement.
